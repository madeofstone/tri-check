# Event Log Analyzer

Extracts and compresses Databricks Spark event logs into compact JSON files focused on actionable tuning metrics.

## Quick Start

```bash
# Analyze an event log
python analyze_eventlog.py <path/to/eventlog>

# Specify custom output path
python analyze_eventlog.py <path/to/eventlog> --output my_analysis.json
```

By default, the output `analysis.json` is written alongside the input file.

## Creating a Study

Each job run gets its own folder under `studies/`:

```
studies/
  my-job-2026-02-14/
    eventlog              # Drop the raw event log here
    analysis.json         # Generated by the script
```

```bash
mkdir -p studies/my-job-2026-02-14
cp /path/to/downloaded/eventlog studies/my-job-2026-02-14/
python analyze_eventlog.py studies/my-job-2026-02-14/eventlog
```

## Output Schema

The compressed JSON contains:

| Section             | Description                                                                                  |
| ------------------- | -------------------------------------------------------------------------------------------- |
| `metadata`          | App ID, Spark version, start time                                                            |
| `summary`           | Top-level stats: total tasks, peak executors, spill/GC/shuffle totals                        |
| `config_snapshot`   | Tuning-relevant Spark properties captured at runtime                                         |
| `resource_profiles` | Executor memory/core configuration                                                           |
| `executor_timeline` | Add/remove events with timestamps and core/memory info                                       |
| `jobs`              | Job-level start/end/result with stage mappings                                               |
| `stages`            | Per-stage aggregated task metrics (run time, CPU, GC, memory, spill, shuffle, I/O, locality) |
| `sql_queries`       | SQL execution IDs, descriptions, and durations                                               |

## Tuning Recommendations

`tuning_recommendations.json` maps each extracted metric to actionable tuning advice, including:

- What the metric tells you
- Which Spark settings to adjust
- Severity rules for automated alerting

This file is designed for UI consumption â€” the frontend can cross-reference analysis results with recommendations to surface optimization suggestions.

## Files

| File                          | Purpose                            |
| ----------------------------- | ---------------------------------- |
| `analyze_eventlog.py`         | Main extraction/compression script |
| `tuning_recommendations.json` | Tuning knowledge base for UI       |
| `README.md`                   | This file                          |
| `studies/`                    | Per-job-run study directories      |
